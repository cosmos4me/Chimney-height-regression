!pip install -q timm
!pip install -q opencv-python-headless

from google.colab import drive
drive.mount('/content/drive') 

import os, json, time
import numpy as np
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from tqdm import tqdm
import timm

TS = "/content/drive/MyDrive/TS_KS.tar"
VS = "/content/drive/MyDrive/VS_KS.tar"
TL = "/content/drive/MyDrive/TL_LINE.tar"
VL = "/content/drive/MyDrive/VL_LINE.tar"

!mkdir -p /content/training_set /content/validation_set /content/tline_label /content/vline_label
fast_extract_tar_and_zip_recursive(TS, "/content/training_set")
fast_extract_tar_and_zip_recursive(VS, "/content/validation_set")
fast_extract_tar_and_zip_recursive(TL, "/content/tline_label")
fast_extract_tar_and_zip_recursive(VL, "/content/vline_label")

def train_main():
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    EPOCHS = 40
    BATCH = 16
    LR = 1e-4

    MODEL_NAME = 'convnext_base'
    DROP_PATH = 0.1
    TRAIN_IMG_DIR = "/content/training_set/"; TRAIN_META_DIR = "/content/tline_label/"
    VAL_IMG_DIR   = "/content/validation_set/"; VAL_META_DIR = "/content/vline_label/"
    SAVE_PATH = "/content/drive/MyDrive/M2_model.pth"

    normalize = transforms.Normalize(
        mean=[0.485, 0.456, 0.406, 0.5, 0.5],
        std =[0.229, 0.224, 0.225, 0.5, 0.5]
    )
    tfm = transforms.Compose([transforms.ToTensor(), normalize])

    train_ds = ImageMaskHeightDataset(TRAIN_IMG_DIR, TRAIN_META_DIR, transform=tfm, compute_stats=True)
    stats = (train_ds.feat_mean, train_ds.feat_std, train_ds.y_mean, train_ds.y_std)
    val_ds   = ImageMaskHeightDataset(VAL_IMG_DIR, VAL_META_DIR, transform=tfm, compute_stats=False, stats=stats)

    tr = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True)
    va = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)

    model = ProbFiLMGate(model_name=MODEL_NAME, pretrained=True, in_chans=5, drop_path_rate=DROP_PATH).to(DEVICE)
    opt = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3)

    best_rmse = 1e9
    warmup_epochs = 4  
    epoch_times = []

    for ep in range(1, EPOCHS + 1):
        ep_start = time.perf_counter()

        # ── Train ───────────────────────────────────────────
        model.train()
        tr_loss = 0.0
        pbar_tr = tqdm(tr, desc=f"Train {ep}/{EPOCHS}", ncols=100)
        for img5, feat_z, y_z in pbar_tr:
            img5, feat_z, y_z = img5.to(DEVICE), feat_z.to(DEVICE), y_z.to(DEVICE)
            opt.zero_grad()
            mu_z, log_var = model(img5, feat_z)
            nll = gaussian_nll(mu_z, log_var.detach(), y_z) if ep <= warmup_epochs else gaussian_nll(mu_z, log_var, y_z)
            loss = nll.mean()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
            opt.step()

            tr_loss += loss.item() * img5.size(0)
            pbar_tr.set_postfix(loss=f"{loss.item():.4f}")

        tr_loss /= len(train_ds)

        # ── Validation ──────────────────────────────────────
        model.eval()
        va_loss = 0.0; preds, gts = [], []
        pbar_va = tqdm(va, desc=f"Valid {ep}/{EPOCHS}", ncols=100, leave=False)
        with torch.no_grad():
            for img5, feat_z, y_z in pbar_va:
                img5, feat_z, y_z = img5.to(DEVICE), feat_z.to(DEVICE), y_z.to(DEVICE)
                mu_z, log_var = model(img5, feat_z)
                nll = gaussian_nll(mu_z, log_var, y_z).mean()
                va_loss += nll.item() * img5.size(0)

                mu = mu_z.cpu().numpy() * stats[3] + stats[2]
                y  = y_z.cpu().numpy()  * stats[3] + stats[2]
                preds.extend(mu.tolist()); gts.extend(y.tolist())

        va_loss /= len(val_ds)
        val_rmse = rmse_np(gts, preds)
        sched.step(val_rmse) 

        ep_time = time.perf_counter() - ep_start
        epoch_times.append(ep_time)
        avg_time = sum(epoch_times) / len(epoch_times)
        remain = avg_time * (EPOCHS - ep)

        print(
            f"Epoch {ep}/{EPOCHS} | Train NLL: {tr_loss:.4f} | Val NLL: {va_loss:.4f} | Val RMSE: {val_rmse:.3f} | "
            f"Epoch time: {ep_time:.1f}s | Avg: {avg_time:.1f}s | Est. remain: {remain/60:.1f} min"
        )

        if val_rmse < best_rmse:
            best_rmse = val_rmse
            torch.save({'model': model.state_dict(), 'stats': stats}, SAVE_PATH)
            print(f"✅ Saved: {SAVE_PATH}  (best RMSE {best_rmse:.3f})")

    print(f"\nDone. Best RMSE: {best_rmse:.3f}")

if __name__ == "__main__":
    train_main()

DEFAULT_CALIB = {"a": 1.0036148953447719, "b": -0.5619141258995768, "tau": 2.5370064952492575}

if __name__ == "__main__":
    eval_from_model_path(
        ckpt_path="/content/drive/MyDrive/M2_model.pth",
        VAL_IMG_DIR="/content/validation_set/",
        VAL_META_DIR="/content/vline_label/",
        model_name="convnext_base",
    )
