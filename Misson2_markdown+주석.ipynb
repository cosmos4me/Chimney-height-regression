{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CJjO7HFVrbe"
      },
      "source": [
        "## 0. 환경 준비 (설치/마운트)\n",
        "- `timm`과 헤드리스 OpenCV는 설치 권장\n",
        "- Google Drive 마운트 후 `/content/drive` 경로 사용\n"
      ],
      "id": "2CJjO7HFVrbe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIWZUWijVrbf",
        "outputId": "f87d555f-8efc-43e8-c179-41da147e848d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 필요한 패키지 설치 (Colab 기본에는 torch/torchvision/numpy/tqdm/cv2 포함)\n",
        "!pip install -q timm\n",
        "!pip install -q opencv-python-headless\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # /content/drive/MyDrive 접근\n"
      ],
      "id": "ZIWZUWijVrbf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORfv24HEVrbg"
      },
      "source": [
        "## 1. 라이브러리 임포트"
      ],
      "id": "ORfv24HEVrbg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt4KDAYhVrbg"
      },
      "outputs": [],
      "source": [
        "import os, json, time\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import timm\n"
      ],
      "id": "pt4KDAYhVrbg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKoTgb9qVrbg"
      },
      "source": [
        "## 2. 데이터 압축 해제 유틸 및 실행\n",
        "### 입력\n",
        "- `.tar` 내부에 `*.zip.part0`가 포함되어 있다고 **가정**합니다.\n",
        "- 각 `zip.part0`만 unzip하면 나머지 분할 파트가 함께 풀립니다.\n",
        "\n",
        "### 출력 폴더\n",
        "- `/content/training_set`, `/content/validation_set`, `/content/tline_label`, `/content/vline_label`\n"
      ],
      "id": "FKoTgb9qVrbg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XpT2YRnVrbh",
        "outputId": "91a3d84a-65f8-4116-fd02-bb35ff5803f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_set completed\n",
            "validation_set completed\n",
            "t label completed\n",
            "v label completed\n",
            "✅ 모든 데이터셋 해제 완료!\n"
          ]
        }
      ],
      "source": [
        "TS = \"/content/drive/MyDrive/TS_KS.tar\"\n",
        "VS = \"/content/drive/MyDrive/VS_KS.tar\"\n",
        "TL = \"/content/drive/MyDrive/TL_LINE.tar\"\n",
        "VL = \"/content/drive/MyDrive/VL_LINE.tar\"\n",
        "\n",
        "def fast_extract_tar_and_zip_recursive(tar_path, output_folder):\n",
        "    \"\"\"\n",
        "    tar_path: .tar 파일 경로(Drive)\n",
        "    output_folder: 최종 unzip 결과물이 들어갈 디렉토리\n",
        "    동작:\n",
        "      1) /content/temp.tar 로 복사 → temp_dir로 전체 해제\n",
        "      2) temp_dir에서 *.zip.part0 파일 검색 → 각각을 output_folder로 unzip(-j로 경로 무시)\n",
        "      3) temp_dir 정리\n",
        "    주의: .tar 내부 구조가 zip 파트들을 포함한다고 가정합니다.\n",
        "    \"\"\"\n",
        "    temp_dir = \"/content/temp_extract\"\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    # .tar를 로컬로 복사 후 해제 (권한/경로 이슈 최소화)\n",
        "    !cp \"{tar_path}\" /content/temp.tar\n",
        "    !tar -xf /content/temp.tar -C \"{temp_dir}\"\n",
        "    !rm /content/temp.tar\n",
        "\n",
        "    # .zip.part0 파일 목록 수집\n",
        "    zip_part0_paths = []\n",
        "    for root, _, files in os.walk(temp_dir):\n",
        "        for f in files:\n",
        "            if f.endswith(\".zip.part0\"):\n",
        "                zip_part0_paths.append(os.path.join(root, f))\n",
        "\n",
        "    if not zip_part0_paths:\n",
        "        print(f\"⚠️ {tar_path} 안에서 zip.part0를 찾을 수 없습니다.\")\n",
        "        !rm -rf \"{temp_dir}\"\n",
        "        return\n",
        "\n",
        "    # 각 분할 zip의 part0만 unzip하면 나머지 part들이 함께 풀림\n",
        "    for zp_path in zip_part0_paths:\n",
        "        !unzip -q -j \"{zp_path}\" -d \"{output_folder}\" 2>/dev/null\n",
        "\n",
        "    # 임시 디렉토리 정리\n",
        "    !rm -rf \"{temp_dir}\"\n",
        "\n",
        "# 출력 폴더 생성(존재해도 무시)\n",
        "!mkdir -p /content/training_set /content/validation_set /content/tline_label /content/vline_label\n",
        "\n",
        "# 실제 압축 해제 실행\n",
        "fast_extract_tar_and_zip_recursive(TS, \"/content/training_set\")\n",
        "print('training_set completed')\n",
        "fast_extract_tar_and_zip_recursive(VS, \"/content/validation_set\")\n",
        "print('validation_set completed')\n",
        "fast_extract_tar_and_zip_recursive(TL, \"/content/tline_label\")\n",
        "print('t label completed')\n",
        "fast_extract_tar_and_zip_recursive(VL, \"/content/vline_label\")\n",
        "print('v label completed')\n",
        "print(\"✅ 모든 데이터셋 해제 완료!\")\n"
      ],
      "id": "1XpT2YRnVrbh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj7DI8WnVrbh"
      },
      "source": [
        "## 3. 전처리 유틸 함수\n",
        "- **Letterbox + padding mask 생성**\n",
        "- **폴리라인 두께**(이미지 크기 기반 동적)\n",
        "- **정규화 길이(feature)** 계산\n"
      ],
      "id": "Lj7DI8WnVrbh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTv4XMSTVrbi"
      },
      "outputs": [],
      "source": [
        "def letterbox_with_padmask(imgC, out_h=224, out_w=224):\n",
        "    \"\"\"\n",
        "    비율 유지(letterbox) 리사이즈 + 중앙 정렬 + 남는 영역 패딩(0) + 패딩 마스크(255=패딩, 0=실제)\n",
        "    입력: imgC (H,W,C)  C=4 (RGB + target_mask)\n",
        "    출력:\n",
        "      - img_lb: (out_h, out_w, C) letterbox된 이미지\n",
        "      - pad_mask: (out_h, out_w) 패딩영역=255, 실제=0 (학습 시 보조 채널로 사용)\n",
        "    \"\"\"\n",
        "    h, w = imgC.shape[:2]\n",
        "    scale = min(out_w / w, out_h / h)\n",
        "    nh, nw = int(round(h * scale)), int(round(w * scale))\n",
        "    resized = cv2.resize(imgC, (nw, nh), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    img_lb = np.zeros((out_h, out_w, imgC.shape[2]), dtype=resized.dtype)\n",
        "    pad_mask = np.ones((out_h, out_w), dtype=np.uint8)  # 기본=1(패딩)\n",
        "\n",
        "    top = (out_h - nh) // 2\n",
        "    left = (out_w - nw) // 2\n",
        "\n",
        "    img_lb[top:top + nh, left:left + nw, :] = resized\n",
        "    pad_mask[top:top + nh, left:left + nw] = 0          # 실제 영역=0\n",
        "\n",
        "    pad_mask = (pad_mask * 255).astype(np.uint8)\n",
        "    return img_lb, pad_mask\n",
        "\n",
        "def dynamic_thickness(h, w, k=0.004):\n",
        "    \"\"\"이미지 크기에 따라 폴리라인 두께를 동적으로 산정(최소 1px)\"\"\"\n",
        "    return max(1, int(k * min(h, w)))\n",
        "\n",
        "def poly_length_norm(all_x, all_y, w, h):\n",
        "    \"\"\"\n",
        "    폴리라인 길이를 (W,H)로 정규화한 총 길이\n",
        "    - all_x/ all_y: 폴리라인 정점 좌표열\n",
        "    - (x/W, y/H)로 스케일 후 인접 세그먼트 길이의 합\n",
        "    \"\"\"\n",
        "    pts = np.stack([np.array(all_x, np.float32) / w,\n",
        "                    np.array(all_y, np.float32) / h], axis=1)\n",
        "    if len(pts) < 2:\n",
        "        return 0.0\n",
        "    seg = np.diff(pts, axis=0)\n",
        "    return float(np.linalg.norm(seg, axis=1).sum())\n"
      ],
      "id": "FTv4XMSTVrbi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5RuRgsCVrbi"
      },
      "source": [
        "## 4. Dataset 정의 (5채널 입력)\n",
        "- **RGB(3) + target_mask(1) + padding_mask(1) = 5채널**\n",
        "- VIA JSON의 `region_attributes.chi_height_m`를 정답으로 사용\n",
        "- 학습셋에서 **길이/타깃 통계**를 추정해 z-정규화, 검증은 그 통계 고정 사용(데이터 누수 방지)\n"
      ],
      "id": "S5RuRgsCVrbi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9xNOSjPVrbj"
      },
      "outputs": [],
      "source": [
        "class ImageMaskHeightDataset(Dataset):\n",
        "    def __init__(self, image_dir, meta_dir, transform=None,\n",
        "                 out_size=(224, 224), compute_stats=False, stats=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.meta_dir = meta_dir\n",
        "        self.transform = transform\n",
        "        self.out_h, self.out_w = out_size\n",
        "        self.samples = []                     # (img_path, all_x, all_y, height_y)\n",
        "        self._feat_list, self._y_list = [], []\n",
        "\n",
        "        # 메타(JSON) 스캔: VIA 형식 가정 (filename, regions[{shape_attributes, region_attributes}])\n",
        "        for meta_file in os.listdir(meta_dir):\n",
        "            if not meta_file.endswith('.json'):\n",
        "                continue\n",
        "            with open(os.path.join(meta_dir, meta_file), 'r') as f:\n",
        "                meta = json.load(f)\n",
        "            for _, v in meta.items():\n",
        "                img_path = os.path.join(image_dir, v['filename'])\n",
        "                if not os.path.exists(img_path):\n",
        "                    continue\n",
        "                for r in v.get('regions', []):\n",
        "                    # 키 'chi_height_m'가 있는 region만 사용(정답 레이블)\n",
        "                    if not r.get('region_attributes') or 'chi_height_m' not in r['region_attributes']:\n",
        "                        continue\n",
        "                    ax = r['shape_attributes'].get('all_points_x', [])\n",
        "                    ay = r['shape_attributes'].get('all_points_y', [])\n",
        "                    if len(ax) < 2:\n",
        "                        continue\n",
        "                    y = float(r['region_attributes']['chi_height_m'])\n",
        "                    self.samples.append((img_path, ax, ay, y))\n",
        "\n",
        "        # 학습용 통계치(폴리라인 길이, 타깃)의 평균/표준편차를 계산 → 정규화에 사용\n",
        "        if compute_stats:\n",
        "            for img_path, ax, ay, y in self.samples:\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    continue\n",
        "                h, w = img.shape[:2]\n",
        "                ln = poly_length_norm(ax, ay, w, h)\n",
        "                self._feat_list.append(ln)\n",
        "                self._y_list.append(y)\n",
        "            self.feat_mean = float(np.mean(self._feat_list))\n",
        "            self.feat_std  = float(np.std(self._feat_list) + 1e-8)\n",
        "            self.y_mean    = float(np.mean(self._y_list))\n",
        "            self.y_std     = float(np.std(self._y_list) + 1e-8)\n",
        "        else:\n",
        "            # 검증/테스트는 학습에서 얻은 stats를 그대로 사용(데이터 누수 방지)\n",
        "            assert stats is not None\n",
        "            self.feat_mean, self.feat_std, self.y_mean, self.y_std = stats\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, ax, ay, y = self.samples[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        # 타깃 폴리라인을 단일 채널 mask(0/255)로 렌더링 (원본 RGB는 변형하지 않음)\n",
        "        mask_tgt = np.zeros((h, w), dtype=np.uint8)\n",
        "        pts_px = np.stack([np.array(ax, np.int32), np.array(ay, np.int32)], axis=1)\n",
        "        cv2.polylines(mask_tgt, [pts_px], isClosed=False, color=255, thickness=dynamic_thickness(h, w))\n",
        "\n",
        "        # 4채널(RGB+mask) → letterbox → pad_mask 생성 → 5채널 합치기\n",
        "        img4 = np.dstack([img, mask_tgt])\n",
        "        img4_lb, pad_mask = letterbox_with_padmask(img4, self.out_h, self.out_w)\n",
        "        img5 = np.dstack([img4_lb, pad_mask])\n",
        "\n",
        "        # 폴리라인 길이(feature)와 타깃을 z-정규화(학습 통계 사용)\n",
        "        length_norm = poly_length_norm(ax, ay, w, h)\n",
        "        feat_z = (length_norm - self.feat_mean) / self.feat_std\n",
        "        y_z    = (y - self.y_mean) / self.y_std\n",
        "\n",
        "        # 텐서 변환\n",
        "        if self.transform is not None:\n",
        "            img_t = self.transform(img5)\n",
        "        else:\n",
        "            img_t = torch.from_numpy(img5.transpose(2, 0, 1)).float() / 255.0\n",
        "\n",
        "        feat_t = torch.tensor([feat_z], dtype=torch.float32)\n",
        "        y_t    = torch.tensor(y_z, dtype=torch.float32)\n",
        "        return img_t, feat_t, y_t\n"
      ],
      "id": "J9xNOSjPVrbj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjE6uspbVrbj"
      },
      "source": [
        "## 5. 모델: ConvNeXt 백본 + FiLM + 게이팅 + 확률 헤드\n",
        "- 입력: `img5`(B, **5**, H, W), `poly_z`(B, 1)\n",
        "- 출력: `mu_z`, `log_var` (정규화된 공간)\n",
        "- **alpha**로 게이팅 강도 조절, `log_var`는 안정성 위해 클램프\n"
      ],
      "id": "sjE6uspbVrbj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZcydZ6QVrbk"
      },
      "outputs": [],
      "source": [
        "class ProbFiLMGate(nn.Module):\n",
        "    def __init__(self, model_name='convnext_tiny', pretrained=True,\n",
        "                 in_chans=5, film_dim=128, gate_dim=128, alpha=0.5,\n",
        "                 logvar_min=-6.0, logvar_max=4.0, drop_path_rate=0.2):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.logvar_min = logvar_min\n",
        "        self.logvar_max = logvar_max\n",
        "\n",
        "        # timm 백본: num_classes=0 → 특징벡터 추출용\n",
        "        self.backbone = timm.create_model(\n",
        "            model_name, pretrained=pretrained, in_chans=in_chans, num_classes=0,\n",
        "            drop_path_rate=drop_path_rate\n",
        "        )\n",
        "        d = self.backbone.num_features\n",
        "\n",
        "        # 길이(feature) → FiLM 파라미터(gamma, beta)\n",
        "        self.len_to_film = nn.Sequential(\n",
        "            nn.Linear(1, film_dim), nn.ReLU(),\n",
        "            nn.Linear(film_dim, 2 * d)\n",
        "        )\n",
        "\n",
        "        # 게이트: [f, poly_z] → 스칼라 게이트 g → (1 + alpha * tanh(g))\n",
        "        self.gate_mlp = nn.Sequential(\n",
        "            nn.Linear(d + 1, 1)\n",
        "        )\n",
        "        # 초기화: 안정화 목적(필요시 강화)\n",
        "        nn.init.zeros_(self.gate_mlp[-1].bias)\n",
        "        nn.init.zeros_(self.len_to_film[-1].weight)\n",
        "        nn.init.zeros_(self.len_to_film[-1].bias)\n",
        "\n",
        "        # 회귀 헤드: [f_film, len_g] → mu_z, log_var\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(d + 1, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, img5, poly_z):\n",
        "        f = self.backbone(img5)  # [B,d]\n",
        "\n",
        "        # FiLM: f * (1+gamma) + beta\n",
        "        film = self.len_to_film(poly_z)              # [B,2d]\n",
        "        gamma, beta = torch.chunk(film, 2, dim=1)    # [B,d], [B,d]\n",
        "        f_film = f * (1 + gamma) + beta\n",
        "\n",
        "        # 길이 게이팅\n",
        "        g = self.gate_mlp(torch.cat([f, poly_z], dim=1))  # [B,1]\n",
        "        gate = 1.0 + self.alpha * torch.tanh(g)\n",
        "        len_g = poly_z * gate\n",
        "\n",
        "        # 확률 회귀 헤드\n",
        "        out = self.head(torch.cat([f_film, len_g], dim=1))  # [B,2]\n",
        "        mu_z, log_var = out[:, 0], out[:, 1]\n",
        "        # 분산 안정화: log_var 클램프\n",
        "        log_var = torch.clamp(log_var, self.logvar_min, self.logvar_max)\n",
        "        return mu_z, log_var\n"
      ],
      "id": "TZcydZ6QVrbk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkaQNzEpVrbk"
      },
      "source": [
        "## 6. 손실/지표 함수\n",
        "- **Gaussian NLL**(평균 사용)\n",
        "- **RMSE** (넘파이 구현)\n"
      ],
      "id": "CkaQNzEpVrbk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5WozkyeVrbk"
      },
      "outputs": [],
      "source": [
        "def gaussian_nll(mu, log_var, target):\n",
        "    \"\"\"정규분포 N(mu, sigma^2) 음의 로그우도(샘플별)\"\"\"\n",
        "    var = torch.exp(log_var)\n",
        "    return 0.5 * (log_var + (target - mu) ** 2 / var)\n",
        "\n",
        "def rmse_np(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n"
      ],
      "id": "N5WozkyeVrbk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr234XbwVrbl"
      },
      "source": [
        "## 7. 학습 루틴\n",
        "- **warmup_epochs** 동안 `log_var` 역전파 차단으로 분산 안정화\n",
        "- Plateau 스케줄러로 LR 감소\n",
        "- Best RMSE 시 체크포인트 저장(`state_dict` + `stats`)\n"
      ],
      "id": "Hr234XbwVrbl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ee35db03099b4cd190efd39f46092165",
            "e1544ceac7834360811efa7927bfab9f",
            "3f8f60d0f72a4422a72b6e3be79a47f0",
            "a07892dcd3644aef967823b8e2f5337e",
            "cb97717c14834acb881a4d57eed223cf",
            "b27a997611df4cb5b3fe0c39a2617caa",
            "6a58b42049364a4eaa0bbe5f20791315",
            "9b9b5a5365b24a10a8c55d10cd5514f8",
            "3ca1cdfe152c4ce1a03af44740feca2d",
            "45b42ba6e9ce4880836db34d0b9813a8",
            "c616634d1ea04429ada690e9c1138816"
          ]
        },
        "id": "JBuVpYvvVrbl",
        "outputId": "3e1f36b8-ef60-41b9-cd5b-01b7fc75f2af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee35db03099b4cd190efd39f46092165"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 1/40: 100%|████████████████████████████████████| 662/662 [07:52<00:00,  1.40it/s, loss=0.2140]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40 | Train NLL: 0.2284 | Val NLL: 0.1914 | Val RMSE: 11.647 | Epoch time: 489.3s | Avg: 489.3s | Est. remain: 318.1 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 11.647)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 2/40: 100%|████████████████████████████████████| 662/662 [07:42<00:00,  1.43it/s, loss=0.1733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/40 | Train NLL: 0.1725 | Val NLL: 0.1707 | Val RMSE: 8.526 | Epoch time: 478.0s | Avg: 483.7s | Est. remain: 306.3 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 8.526)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 3/40: 100%|████████████████████████████████████| 662/662 [07:42<00:00,  1.43it/s, loss=0.1851]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/40 | Train NLL: 0.1665 | Val NLL: 0.1800 | Val RMSE: 8.457 | Epoch time: 478.4s | Avg: 481.9s | Est. remain: 297.2 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 8.457)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 4/40: 100%|████████████████████████████████████| 662/662 [07:47<00:00,  1.42it/s, loss=0.1820]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/40 | Train NLL: 0.1657 | Val NLL: 0.1786 | Val RMSE: 6.797 | Epoch time: 483.2s | Avg: 482.2s | Est. remain: 289.3 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 6.797)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 5/40: 100%|███████████████████████████████████| 662/662 [07:44<00:00,  1.42it/s, loss=-1.5008]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/40 | Train NLL: -0.9483 | Val NLL: -1.2458 | Val RMSE: 9.075 | Epoch time: 480.8s | Avg: 481.9s | Est. remain: 281.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 6/40: 100%|███████████████████████████████████| 662/662 [07:42<00:00,  1.43it/s, loss=-1.3275]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/40 | Train NLL: -1.4569 | Val NLL: -1.2387 | Val RMSE: 8.488 | Epoch time: 478.1s | Avg: 481.3s | Est. remain: 272.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 7/40: 100%|███████████████████████████████████| 662/662 [07:42<00:00,  1.43it/s, loss=-1.6479]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/40 | Train NLL: -1.6739 | Val NLL: -1.6207 | Val RMSE: 7.054 | Epoch time: 477.9s | Avg: 480.8s | Est. remain: 264.4 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 8/40: 100%|███████████████████████████████████| 662/662 [07:42<00:00,  1.43it/s, loss=-1.7176]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/40 | Train NLL: -1.8365 | Val NLL: -1.3495 | Val RMSE: 7.550 | Epoch time: 478.6s | Avg: 480.5s | Est. remain: 256.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 9/40: 100%|███████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.5834]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/40 | Train NLL: -2.1149 | Val NLL: -1.7331 | Val RMSE: 5.501 | Epoch time: 478.8s | Avg: 480.3s | Est. remain: 248.2 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 5.501)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 10/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.43it/s, loss=-2.1788]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/40 | Train NLL: -2.2703 | Val NLL: -1.5456 | Val RMSE: 5.507 | Epoch time: 480.4s | Avg: 480.3s | Est. remain: 240.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 11/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.43it/s, loss=-2.6093]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/40 | Train NLL: -2.3448 | Val NLL: -1.8396 | Val RMSE: 5.033 | Epoch time: 479.8s | Avg: 480.3s | Est. remain: 232.1 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 5.033)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 12/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.43it/s, loss=-2.3872]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/40 | Train NLL: -2.4078 | Val NLL: -1.6303 | Val RMSE: 5.147 | Epoch time: 480.4s | Avg: 480.3s | Est. remain: 224.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 13/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.3258]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/40 | Train NLL: -2.4159 | Val NLL: -1.5796 | Val RMSE: 5.228 | Epoch time: 479.2s | Avg: 480.2s | Est. remain: 216.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 14/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.2994]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/40 | Train NLL: -2.4377 | Val NLL: -1.7281 | Val RMSE: 4.830 | Epoch time: 479.3s | Avg: 480.1s | Est. remain: 208.1 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.830)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 15/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.43it/s, loss=-2.5339]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/40 | Train NLL: -2.4670 | Val NLL: -1.5728 | Val RMSE: 4.993 | Epoch time: 480.0s | Avg: 480.1s | Est. remain: 200.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 16/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.5173]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/40 | Train NLL: -2.4936 | Val NLL: -1.3140 | Val RMSE: 5.292 | Epoch time: 478.9s | Avg: 480.1s | Est. remain: 192.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 17/40: 100%|██████████████████████████████████| 662/662 [07:42<00:00,  1.43it/s, loss=-2.5308]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/40 | Train NLL: -2.5372 | Val NLL: -1.4811 | Val RMSE: 5.152 | Epoch time: 478.6s | Avg: 480.0s | Est. remain: 184.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 18/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.7824]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/40 | Train NLL: -2.5452 | Val NLL: -1.5650 | Val RMSE: 4.975 | Epoch time: 478.9s | Avg: 479.9s | Est. remain: 176.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 19/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.9245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/40 | Train NLL: -2.6663 | Val NLL: -1.5305 | Val RMSE: 4.729 | Epoch time: 479.6s | Avg: 479.9s | Est. remain: 168.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.729)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 20/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.43it/s, loss=-2.8183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/40 | Train NLL: -2.7467 | Val NLL: -1.7173 | Val RMSE: 4.398 | Epoch time: 480.0s | Avg: 479.9s | Est. remain: 160.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.398)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 21/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.43it/s, loss=-2.5121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/40 | Train NLL: -2.7707 | Val NLL: -1.6561 | Val RMSE: 4.474 | Epoch time: 480.3s | Avg: 479.9s | Est. remain: 152.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 22/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.8500]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/40 | Train NLL: -2.7865 | Val NLL: -1.7154 | Val RMSE: 4.344 | Epoch time: 479.3s | Avg: 479.9s | Est. remain: 144.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.344)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 23/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.42it/s, loss=-2.8137]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/40 | Train NLL: -2.7920 | Val NLL: -1.7122 | Val RMSE: 4.395 | Epoch time: 480.3s | Avg: 479.9s | Est. remain: 136.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 24/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.8647]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/40 | Train NLL: -2.8055 | Val NLL: -1.6644 | Val RMSE: 4.480 | Epoch time: 479.2s | Avg: 479.9s | Est. remain: 128.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 25/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.43it/s, loss=-2.8944]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/40 | Train NLL: -2.8109 | Val NLL: -1.7973 | Val RMSE: 4.309 | Epoch time: 479.8s | Avg: 479.9s | Est. remain: 120.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.309)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 26/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.43it/s, loss=-2.9140]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/40 | Train NLL: -2.8186 | Val NLL: -1.7150 | Val RMSE: 4.336 | Epoch time: 480.2s | Avg: 479.9s | Est. remain: 112.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 27/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.7016]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/40 | Train NLL: -2.8185 | Val NLL: -1.7249 | Val RMSE: 4.359 | Epoch time: 479.6s | Avg: 479.9s | Est. remain: 104.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 28/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.7850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/40 | Train NLL: -2.8279 | Val NLL: -1.7489 | Val RMSE: 4.362 | Epoch time: 479.2s | Avg: 479.9s | Est. remain: 96.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 29/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.8012]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/40 | Train NLL: -2.8377 | Val NLL: -1.7433 | Val RMSE: 4.296 | Epoch time: 478.9s | Avg: 479.8s | Est. remain: 88.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.296)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 30/40: 100%|██████████████████████████████████| 662/662 [07:45<00:00,  1.42it/s, loss=-2.8329]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/40 | Train NLL: -2.8389 | Val NLL: -1.7063 | Val RMSE: 4.287 | Epoch time: 481.0s | Avg: 479.9s | Est. remain: 80.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.287)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 31/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.6518]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/40 | Train NLL: -2.8426 | Val NLL: -1.6926 | Val RMSE: 4.386 | Epoch time: 479.2s | Avg: 479.8s | Est. remain: 72.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 32/40: 100%|██████████████████████████████████| 662/662 [07:42<00:00,  1.43it/s, loss=-2.8451]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/40 | Train NLL: -2.8449 | Val NLL: -1.6612 | Val RMSE: 4.383 | Epoch time: 478.4s | Avg: 479.8s | Est. remain: 64.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 33/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.7904]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/40 | Train NLL: -2.8482 | Val NLL: -1.7285 | Val RMSE: 4.341 | Epoch time: 478.7s | Avg: 479.8s | Est. remain: 56.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 34/40: 100%|██████████████████████████████████| 662/662 [07:42<00:00,  1.43it/s, loss=-2.9371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/40 | Train NLL: -2.8488 | Val NLL: -1.7082 | Val RMSE: 4.298 | Epoch time: 478.6s | Avg: 479.7s | Est. remain: 48.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 35/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.8644]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/40 | Train NLL: -2.8856 | Val NLL: -1.7650 | Val RMSE: 4.276 | Epoch time: 478.9s | Avg: 479.7s | Est. remain: 40.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.276)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 36/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.8938]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/40 | Train NLL: -2.9128 | Val NLL: -1.7280 | Val RMSE: 4.260 | Epoch time: 479.7s | Avg: 479.7s | Est. remain: 32.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.260)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 37/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.9745]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/40 | Train NLL: -2.9245 | Val NLL: -1.7573 | Val RMSE: 4.198 | Epoch time: 479.0s | Avg: 479.7s | Est. remain: 24.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.198)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 38/40: 100%|██████████████████████████████████| 662/662 [07:43<00:00,  1.43it/s, loss=-2.9152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/40 | Train NLL: -2.9273 | Val NLL: -1.7525 | Val RMSE: 4.232 | Epoch time: 479.3s | Avg: 479.7s | Est. remain: 16.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 39/40: 100%|██████████████████████████████████| 662/662 [07:42<00:00,  1.43it/s, loss=-2.9582]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/40 | Train NLL: -2.9286 | Val NLL: -1.7627 | Val RMSE: 4.283 | Epoch time: 478.5s | Avg: 479.6s | Est. remain: 8.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 40/40: 100%|██████████████████████████████████| 662/662 [07:44<00:00,  1.43it/s, loss=-2.9471]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/40 | Train NLL: -2.9364 | Val NLL: -1.7644 | Val RMSE: 4.098 | Epoch time: 480.1s | Avg: 479.7s | Est. remain: 0.0 min\n",
            "✅ Saved: /content/drive/MyDrive/M2_model.pth  (best RMSE 4.098)\n",
            "\n",
            "Done. Best RMSE: 4.098\n"
          ]
        }
      ],
      "source": [
        "def train_main():\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    EPOCHS = 40\n",
        "    BATCH = 16\n",
        "    LR = 1e-4\n",
        "\n",
        "    MODEL_NAME = 'convnext_base'\n",
        "    DROP_PATH = 0.1\n",
        "    TRAIN_IMG_DIR = \"/content/training_set/\"; TRAIN_META_DIR = \"/content/tline_label/\"\n",
        "    VAL_IMG_DIR   = \"/content/validation_set/\"; VAL_META_DIR = \"/content/vline_label/\"\n",
        "    SAVE_PATH = \"/content/drive/MyDrive/M2_model.pth\"\n",
        "\n",
        "    # 5채널 정규화(mean/std): RGB는 ImageNet 통계, mask/pad는 0.5/0.5로 스케일링\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406, 0.5, 0.5],\n",
        "        std =[0.229, 0.224, 0.225, 0.5, 0.5]\n",
        "    )\n",
        "    tfm = transforms.Compose([transforms.ToTensor(), normalize])\n",
        "\n",
        "    # Dataset 생성: 학습에서 통계 추정 → 검증은 동일 통계 사용\n",
        "    train_ds = ImageMaskHeightDataset(TRAIN_IMG_DIR, TRAIN_META_DIR, transform=tfm, compute_stats=True)\n",
        "    stats = (train_ds.feat_mean, train_ds.feat_std, train_ds.y_mean, train_ds.y_std)\n",
        "    val_ds   = ImageMaskHeightDataset(VAL_IMG_DIR, VAL_META_DIR, transform=tfm, compute_stats=False, stats=stats)\n",
        "\n",
        "    # DataLoader: 학습은 shuffle=True, 검증은 False\n",
        "    tr = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    va = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # 모델/옵티마/스케줄러\n",
        "    model = ProbFiLMGate(model_name=MODEL_NAME, pretrained=True, in_chans=5, drop_path_rate=DROP_PATH).to(DEVICE)\n",
        "    opt = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "    sched = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "    best_rmse = 1e9\n",
        "    warmup_epochs = 4  # 초반엔 log_var 역전파 차단으로 안정화\n",
        "    epoch_times = []\n",
        "\n",
        "    for ep in range(1, EPOCHS + 1):\n",
        "        ep_start = time.perf_counter()\n",
        "\n",
        "        # ── Train ───────────────────────────────────────────\n",
        "        model.train()\n",
        "        tr_loss = 0.0\n",
        "        pbar_tr = tqdm(tr, desc=f\"Train {ep}/{EPOCHS}\", ncols=100)\n",
        "        for img5, feat_z, y_z in pbar_tr:\n",
        "            img5, feat_z, y_z = img5.to(DEVICE), feat_z.to(DEVICE), y_z.to(DEVICE)\n",
        "            opt.zero_grad()\n",
        "            mu_z, log_var = model(img5, feat_z)\n",
        "            # warmup 동안 분산 고정: log_var 그래프 분리(detach)\n",
        "            nll = gaussian_nll(mu_z, log_var.detach(), y_z) if ep <= warmup_epochs else gaussian_nll(mu_z, log_var, y_z)\n",
        "            loss = nll.mean()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "            opt.step()\n",
        "\n",
        "            tr_loss += loss.item() * img5.size(0)\n",
        "            pbar_tr.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "        tr_loss /= len(train_ds)\n",
        "\n",
        "        # ── Validation ──────────────────────────────────────\n",
        "        model.eval()\n",
        "        va_loss = 0.0; preds, gts = [], []\n",
        "        pbar_va = tqdm(va, desc=f\"Valid {ep}/{EPOCHS}\", ncols=100, leave=False)\n",
        "        with torch.no_grad():\n",
        "            for img5, feat_z, y_z in pbar_va:\n",
        "                img5, feat_z, y_z = img5.to(DEVICE), feat_z.to(DEVICE), y_z.to(DEVICE)\n",
        "                mu_z, log_var = model(img5, feat_z)\n",
        "                nll = gaussian_nll(mu_z, log_var, y_z).mean()\n",
        "                va_loss += nll.item() * img5.size(0)\n",
        "\n",
        "                # 정규화 역변환(mu_z → 물리 단위, y_z → 물리 단위)\n",
        "                mu = mu_z.cpu().numpy() * stats[3] + stats[2]\n",
        "                y  = y_z.cpu().numpy()  * stats[3] + stats[2]\n",
        "                preds.extend(mu.tolist()); gts.extend(y.tolist())\n",
        "\n",
        "        va_loss /= len(val_ds)\n",
        "        val_rmse = rmse_np(gts, preds)\n",
        "        sched.step(val_rmse)  # plateau 시 LR 감소\n",
        "\n",
        "        # 진행 시간 로깅(평균 시간으로 잔여 추정)\n",
        "        ep_time = time.perf_counter() - ep_start\n",
        "        epoch_times.append(ep_time)\n",
        "        avg_time = sum(epoch_times) / len(epoch_times)\n",
        "        remain = avg_time * (EPOCHS - ep)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {ep}/{EPOCHS} | Train NLL: {tr_loss:.4f} | Val NLL: {va_loss:.4f} | Val RMSE: {val_rmse:.3f} | \"\n",
        "            f\"Epoch time: {ep_time:.1f}s | Avg: {avg_time:.1f}s | Est. remain: {remain/60:.1f} min\"\n",
        "        )\n",
        "\n",
        "        # 베스트 모델 저장(백본 가중치+통계치)\n",
        "        if val_rmse < best_rmse:\n",
        "            best_rmse = val_rmse\n",
        "            torch.save({'model': model.state_dict(), 'stats': stats}, SAVE_PATH)\n",
        "            print(f\"✅ Saved: {SAVE_PATH}  (best RMSE {best_rmse:.3f})\")\n",
        "\n",
        "    print(f\"\\nDone. Best RMSE: {best_rmse:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_main()\n"
      ],
      "id": "JBuVpYvvVrbl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xDiWdyuVrbl"
      },
      "source": [
        "> epoch = 40에서 RMSE≈4.098이 관측되었다(실행 환경/시드에 따라 변동 가능)."
      ],
      "id": "4xDiWdyuVrbl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8_nvqqXVrbm"
      },
      "source": [
        "## 8. 평가/추론 (선형 보정 포함)\n",
        "- 체크포인트(`state_dict` + `stats`) 로드\n",
        "- `mu`(평균)과 `sigma`(불확실성)를 물리 단위로 역변환\n",
        "- 선택적으로 `a,b` 선형 보정\n"
      ],
      "id": "j8_nvqqXVrbm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH69Y7pcVrbm",
        "outputId": "0e7cfcd3-f04e-4d54-c1dc-24bf395c0012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE(base):  4.098\n",
            "RMSE(mu-cal): 4.091\n"
          ]
        }
      ],
      "source": [
        "DEFAULT_CALIB = {\"a\": 1.0036148953447719, \"b\": -0.5619141258995768, \"tau\": 2.5370064952492575}\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_from_model_path(ckpt_path,\n",
        "                         VAL_IMG_DIR=\"/content/validation_set/\",\n",
        "                         VAL_META_DIR=\"/content/vline_label/\",\n",
        "                         model_name=\"convnext_base\",\n",
        "                         in_chans=5,\n",
        "                         drop_path_rate=0.1,\n",
        "                         batch_size=16,\n",
        "                         num_workers=2):\n",
        "    \"\"\"\n",
        "    저장된 체크포인트(가중치+통계)를 불러와 검증셋 RMSE 산출\n",
        "    - preds: 정규화 역변환된 평균(mu)\n",
        "    - sigmas: 예측 불확실성(y_std * sqrt(exp(log_var)))\n",
        "    - (선택) 선형 보정 y' = a*pred + b 적용 시 RMSE(mu-cal) 출력\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    ckpt  = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    state = ckpt.get(\"model\", ckpt)\n",
        "    stats = ckpt[\"stats\"]                       # (feat_mean, feat_std, y_mean, y_std)\n",
        "    y_mean, y_std = stats[2], stats[3]\n",
        "\n",
        "    calib = ckpt.get(\"calib\", DEFAULT_CALIB)\n",
        "    a, b, tau = float(calib[\"a\"]), float(calib[\"b\"]), float(calib[\"tau\"])\n",
        "\n",
        "    normalize = transforms.Normalize(mean=[0.485,0.456,0.406,0.5,0.5],\n",
        "                                     std =[0.229,0.224,0.225,0.5,0.5])\n",
        "    tfm = transforms.Compose([transforms.ToTensor(), normalize])\n",
        "\n",
        "    val_ds = ImageMaskHeightDataset(VAL_IMG_DIR, VAL_META_DIR, transform=tfm, compute_stats=False, stats=stats)\n",
        "    va = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    # 평가 시에는 pretrained=False (학습된 state로 덮어쓰기 때문)\n",
        "    model = ProbFiLMGate(model_name=model_name, pretrained=False, in_chans=in_chans, drop_path_rate=drop_path_rate).to(device)\n",
        "    model.load_state_dict(state, strict=False)\n",
        "    model.eval()\n",
        "\n",
        "    preds, sigmas, gts = [], [], []\n",
        "    for img5, feat_z, y_z in va:\n",
        "        img5, feat_z, y_z = img5.to(device), feat_z.to(device), y_z.to(device)\n",
        "        mu_z, log_var = model(img5, feat_z)\n",
        "        # 정규화 역변환\n",
        "        mu_m    = (mu_z.cpu().numpy() * y_std) + y_mean\n",
        "        sigma_m =  y_std * np.sqrt(np.exp(log_var.cpu().numpy()))\n",
        "        y_m     = (y_z.cpu().numpy()  * y_std) + y_mean\n",
        "        preds.extend(mu_m.tolist()); sigmas.extend(sigma_m.tolist()); gts.extend(y_m.tolist())\n",
        "\n",
        "    preds   = np.array(preds)\n",
        "    sigmas  = np.array(sigmas)\n",
        "    gts     = np.array(gts)\n",
        "\n",
        "    rmse = lambda a_, b_: float(np.sqrt(np.mean((a_ - b_)**2)))\n",
        "    rmse_base   = rmse(preds, gts)\n",
        "    rmse_mu_cal = rmse(a * preds + b, gts)\n",
        "\n",
        "    print(f\"RMSE(base):  {rmse_base:.3f}\")\n",
        "    print(f\"RMSE(mu-cal): {rmse_mu_cal:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    eval_from_model_path(\n",
        "        ckpt_path=\"/content/drive/MyDrive/M2_model.pth\",\n",
        "        VAL_IMG_DIR=\"/content/validation_set/\",\n",
        "        VAL_META_DIR=\"/content/vline_label/\",\n",
        "        model_name=\"convnext_base\",\n",
        "    )\n"
      ],
      "id": "NH69Y7pcVrbm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mmsgO0VVrbm"
      },
      "source": [
        "### 참고\n",
        "- 예: `RMSE(base) ≈ 4.098 → 선형 보정 후 RMSE(mu-cal) ≈ 4.091`\n",
        "- 실행/시드/하드웨어에 따라 수치는 변동될 수 있습니다.\n"
      ],
      "id": "-mmsgO0VVrbm"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee35db03099b4cd190efd39f46092165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1544ceac7834360811efa7927bfab9f",
              "IPY_MODEL_3f8f60d0f72a4422a72b6e3be79a47f0",
              "IPY_MODEL_a07892dcd3644aef967823b8e2f5337e"
            ],
            "layout": "IPY_MODEL_cb97717c14834acb881a4d57eed223cf"
          }
        },
        "e1544ceac7834360811efa7927bfab9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b27a997611df4cb5b3fe0c39a2617caa",
            "placeholder": "​",
            "style": "IPY_MODEL_6a58b42049364a4eaa0bbe5f20791315",
            "value": "model.safetensors: 100%"
          }
        },
        "3f8f60d0f72a4422a72b6e3be79a47f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9b5a5365b24a10a8c55d10cd5514f8",
            "max": 354400320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ca1cdfe152c4ce1a03af44740feca2d",
            "value": 354400320
          }
        },
        "a07892dcd3644aef967823b8e2f5337e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45b42ba6e9ce4880836db34d0b9813a8",
            "placeholder": "​",
            "style": "IPY_MODEL_c616634d1ea04429ada690e9c1138816",
            "value": " 354M/354M [00:04&lt;00:00, 126MB/s]"
          }
        },
        "cb97717c14834acb881a4d57eed223cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b27a997611df4cb5b3fe0c39a2617caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a58b42049364a4eaa0bbe5f20791315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b9b5a5365b24a10a8c55d10cd5514f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca1cdfe152c4ce1a03af44740feca2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45b42ba6e9ce4880836db34d0b9813a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c616634d1ea04429ada690e9c1138816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}